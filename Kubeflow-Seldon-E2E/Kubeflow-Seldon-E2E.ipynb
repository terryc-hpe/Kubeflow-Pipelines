{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/cdcd253e-0471-48d8-a750-e836de57b492\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/1372ea07-e009-463c-9056-38d57d5b5c5b\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=1372ea07-e009-463c-9056-38d57d5b5c5b)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kfp.dsl as dsl\n",
    "import yaml, kfp\n",
    "from kubernetes import client as k8s\n",
    "from kfp import onprem\n",
    "\n",
    "PVC_NAME = \"nlp-example-pvc\"\n",
    "MOUNT = \"/mnt\"\n",
    "\n",
    "#Please update below tag if you rebuild the images using build.sh script\n",
    "EXTRACT_STEP_IMAGE=\"prawat5/features_extractor:1.0\"\n",
    "CLEAN_STEP_IMAGE=\"prawat5/clean_text_transformer:1.0\"\n",
    "TOKENIZE_STEP_IMAGE=\"prawat5/spacy_tokenizer:1.0\"\n",
    "VECTORIZE_STEP_IMAGE=\"prawat5/tfidf_vectorizer:1.0\"\n",
    "PREDICT_STEP_IMAGE=\"prawat5/lr_text_classifier:1.0\"\n",
    "\n",
    "DATA = {\n",
    "    \"EXTRACT_STEP_IMAGE\": EXTRACT_STEP_IMAGE, \n",
    "    \"CLEAN_STEP_IMAGE\": CLEAN_STEP_IMAGE,\n",
    "    \"TOKENIZE_STEP_IMAGE\": TOKENIZE_STEP_IMAGE,\n",
    "    \"VECTORIZE_STEP_IMAGE\": VECTORIZE_STEP_IMAGE,\n",
    "    \"PREDICT_STEP_IMAGE\": PREDICT_STEP_IMAGE,\n",
    "    \"PVC_NAME\": PVC_NAME\n",
    "}\n",
    "\n",
    "SELDON_DEPLOYMENT_YAML = \"\"\"\n",
    "apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  labels:\n",
    "    app: seldon\n",
    "  name: \"seldon-deployment-{{{{workflow.name}}}}\"\n",
    "  namespace: kubeflow\n",
    "spec:\n",
    "  annotations:\n",
    "    project_name: NLP Pipeline\n",
    "    deployment_version: v1\n",
    "  name: \"seldon-deployment-{{{{workflow.name}}}}\"\n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - image: {CLEAN_STEP_IMAGE}\n",
    "          imagePullPolicy: IfNotPresent\n",
    "          name: cleantext\n",
    "          resources:\n",
    "            requests:\n",
    "              memory: 1Mi\n",
    "        - image: {TOKENIZE_STEP_IMAGE}\n",
    "          imagePullPolicy: IfNotPresent\n",
    "          name: spacytokenizer\n",
    "        - image: {VECTORIZE_STEP_IMAGE}\n",
    "          imagePullPolicy: IfNotPresent\n",
    "          name: tfidfvectorizer\n",
    "          volumeMounts:\n",
    "          - name: mypvc\n",
    "            mountPath: /mnt\n",
    "        - image: {PREDICT_STEP_IMAGE}\n",
    "          imagePullPolicy: IfNotPresent\n",
    "          name: lrclassifier\n",
    "          volumeMounts:\n",
    "          - name: mypvc\n",
    "            mountPath: /mnt\n",
    "        terminationGracePeriodSeconds: 20\n",
    "        volumes:\n",
    "        - name: mypvc\n",
    "          persistentVolumeClaim:\n",
    "            claimName: \"{PVC_NAME}\"\n",
    "    graph:\n",
    "      children:\n",
    "      - name: spacytokenizer\n",
    "        endpoint:\n",
    "          type: REST\n",
    "        type: MODEL\n",
    "        children:\n",
    "        - name: tfidfvectorizer\n",
    "          endpoint:\n",
    "            type: REST\n",
    "          type: MODEL\n",
    "          children:\n",
    "          - name: lrclassifier\n",
    "            endpoint:\n",
    "              type: REST\n",
    "            type: MODEL\n",
    "            children: []\n",
    "      name: cleantext\n",
    "      endpoint:\n",
    "        type: REST\n",
    "      type: MODEL\n",
    "    name: single-model\n",
    "    replicas: 1\n",
    "    annotations:\n",
    "      predictor_version: v1\n",
    "\"\"\"\n",
    "\n",
    "SELDON_DEPLOYMENT_YAML = SELDON_DEPLOYMENT_YAML.format(**DATA)\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "  name='NLP',\n",
    "  description='A pipeline demonstrating reproducible steps for NLP'\n",
    ")\n",
    "def nlp_pipeline(\n",
    "        csv_url=\"reddit_train.csv\",\n",
    "        csv_encoding=\"ISO-8859-1\",\n",
    "        features_column=\"BODY\",\n",
    "        labels_column=\"REMOVED\",\n",
    "        raw_text_path='text.data',\n",
    "        labels_path='labels.data',\n",
    "        clean_text_path='clean.data',\n",
    "        spacy_tokens_path='tokens.data',\n",
    "        tfidf_vectors_path='tfidf.data',\n",
    "        lr_prediction_path='prediction.data',\n",
    "        tfidf_model_path='tfidf.model',\n",
    "        lr_model_path='lr.model',\n",
    "        lr_c_param=0.1,\n",
    "        tfidf_max_features=10000,\n",
    "        tfidf_ngram_range=3,\n",
    "        batch_size='100'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Pipeline \n",
    "    \"\"\"\n",
    "    \n",
    "    csv_url = MOUNT + \"/\" + str(csv_url)\n",
    "    raw_text_path = MOUNT + \"/\" + str(raw_text_path)\n",
    "    labels_path = MOUNT + \"/\" + str(labels_path)\n",
    "    clean_text_path = MOUNT + \"/\" + str(clean_text_path)\n",
    "    spacy_tokens_path = MOUNT + \"/\" + str(spacy_tokens_path)\n",
    "    tfidf_vectors_path = MOUNT + \"/\" + str(tfidf_vectors_path)\n",
    "    lr_prediction_path = MOUNT + \"/\" + str(lr_prediction_path)\n",
    "    tfidf_model_path = MOUNT + \"/\" + str(tfidf_model_path)\n",
    "    lr_model_path = MOUNT + \"/\" + str(lr_model_path)\n",
    "    \n",
    "    \n",
    "    extract_step = dsl.ContainerOp(\n",
    "        name='Extract Features and Labels',\n",
    "        image=EXTRACT_STEP_IMAGE,\n",
    "        command=\"python\",\n",
    "        arguments=[\n",
    "            \"/microservice/pipeline_step.py\",\n",
    "            \"--labels-path\", labels_path,\n",
    "            \"--features-path\", raw_text_path,\n",
    "            \"--csv-url\", csv_url,\n",
    "            \"--csv-encoding\", csv_encoding,\n",
    "            \"--features-column\", features_column,\n",
    "            \"--labels-column\", labels_column\n",
    "        ]\n",
    "    ).apply(onprem.mount_pvc(PVC_NAME, 'local-storage', MOUNT))\n",
    "\n",
    "    clean_step = dsl.ContainerOp(\n",
    "        name='Clean The Data',\n",
    "        image=CLEAN_STEP_IMAGE,\n",
    "        command=\"python\",\n",
    "        arguments=[\n",
    "            \"/microservice/pipeline_step.py\",\n",
    "            \"--in-path\", raw_text_path,\n",
    "            \"--out-path\", clean_text_path,\n",
    "        ]\n",
    "    ).apply(onprem.mount_pvc(PVC_NAME, 'local-storage', MOUNT))\n",
    "    \n",
    "    clean_step.after(extract_step)\n",
    "    \n",
    "    tokenize_step = dsl.ContainerOp(\n",
    "        name='Tokenize the Data',\n",
    "        image=TOKENIZE_STEP_IMAGE,\n",
    "        command=\"python\",\n",
    "        arguments=[\n",
    "            \"/microservice/pipeline_step.py\",\n",
    "            \"--in-path\", clean_text_path,\n",
    "            \"--out-path\", spacy_tokens_path,\n",
    "        ]\n",
    "    ).apply(onprem.mount_pvc(PVC_NAME, 'local-storage', MOUNT))\n",
    "    \n",
    "    tokenize_step.after(clean_step)\n",
    "\n",
    "    vectorize_step = dsl.ContainerOp(\n",
    "        name='Train using TF-IDF Vectorizer',\n",
    "        image=VECTORIZE_STEP_IMAGE,\n",
    "        command=\"python\",\n",
    "        arguments=[\n",
    "            \"/microservice/pipeline_step.py\",\n",
    "            \"--in-path\", spacy_tokens_path,\n",
    "            \"--out-path\", tfidf_vectors_path,\n",
    "            \"--max-features\", tfidf_max_features,\n",
    "            \"--ngram-range\", tfidf_ngram_range,\n",
    "            \"--action\", \"train\",\n",
    "            \"--model-path\", tfidf_model_path,\n",
    "        ]\n",
    "    ).apply(onprem.mount_pvc(PVC_NAME, 'local-storage', MOUNT))\n",
    "    \n",
    "    vectorize_step.after(tokenize_step)\n",
    "\n",
    "    predict_step = dsl.ContainerOp(\n",
    "        name='Predict-Logistic Regression Classifier',\n",
    "        image=PREDICT_STEP_IMAGE,\n",
    "        command=\"python\",\n",
    "        arguments=[\n",
    "            \"/microservice/pipeline_step.py\",\n",
    "            \"--in-path\", tfidf_vectors_path,\n",
    "            \"--labels-path\", labels_path,\n",
    "            \"--out-path\", lr_prediction_path,\n",
    "            \"--c-param\", lr_c_param,\n",
    "            \"--action\", \"train\",\n",
    "            \"--model-path\", lr_model_path,\n",
    "        ]\n",
    "    ).apply(onprem.mount_pvc(PVC_NAME, 'local-storage', MOUNT))\n",
    "    \n",
    "    predict_step.after(vectorize_step)\n",
    "    \n",
    "    \n",
    "    seldon_config = yaml.safe_load(SELDON_DEPLOYMENT_YAML)\n",
    "\n",
    "    deploy_step = dsl.ResourceOp(\n",
    "        name=\"Seldon-Deployment\",\n",
    "        k8s_resource=seldon_config,\n",
    "        attribute_outputs={\"name\": \"{.metadata.name}\"})\n",
    "\n",
    "    deploy_step.after(predict_step)\n",
    "    \n",
    "\n",
    "kfp.Client().create_run_from_pipeline_func(\n",
    "    nlp_pipeline,\n",
    "    experiment_name=\"Test\",\n",
    "    arguments={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
